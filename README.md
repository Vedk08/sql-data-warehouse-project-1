# sql-data-warehouse-project-1
Building a modern data warehouse with Postgres Sql Server, including ETL processes, data modelling, transformations and analytics.

---

## ğŸ—ï¸ Data Architecture

This project follows the **Medallion Architecture** pattern with **Bronze**, **Silver**, and **Gold** layers:

### Bronze Layer
- Stores raw data exactly as received from source systems  
- Data is ingested from CSV files into PostgreSQL with no transformations  

### Silver Layer
- Cleansed and standardized data  
- Handles data quality issues such as missing values, duplicates, and inconsistent formats  

### Gold Layer
- Business-ready data modeled using a **star schema**  
- Optimized for analytical queries and reporting  

This layered approach improves **data quality, maintainability, and scalability**.

---

## ğŸ“– Project Overview

This project covers the full lifecycle of a modern analytics system:

1. **Data Architecture Design**  
   - Designing a data warehouse using the Medallion Architecture  

2. **ETL Pipelines**  
   - Loading raw data into PostgreSQL  
   - Transforming data across Bronze â†’ Silver â†’ Gold layers  

3. **Data Modeling**  
   - Designing fact and dimension tables  
   - Implementing a star schema for analytics  

4. **Analytics & Reporting**  
   - Writing SQL queries to analyze customer behavior, product performance, and sales trends  

ğŸ¯ This project demonstrates skills relevant to:
- Data Engineering  
- Analytics Engineering  
- SQL Development  
- Data Modeling  
- Business Intelligence & Reporting  

---

## ğŸ¤– Use of AI in This Project

Artificial Intelligence (AI) tools were **actively used throughout this project** to improve productivity and code quality.

AI was used to:
- Assist in writing SQL queries and transformations  
- Help debug SQL logic and resolve errors  
- Refactor queries for improved readability and performance  
- Validate data modeling decisions and architectural choices  

All AI-assisted code was:
- **Reviewed, tested, and modified manually**
- Adapted to the specific requirements of the project
- Fully understood and owned by the author  

This reflects a **modern, AI-augmented development workflow**, where AI is used as a productivity tool rather than a replacement for core data engineering skills.

---

## ğŸ› ï¸ Tools & Technologies

All tools used in this project are **free and open-source**:

- **PostgreSQL** â€“ Primary data warehouse database  
- **pgAdmin / DBeaver** â€“ Database management and querying  
- **CSV Files** â€“ Source data (ERP & CRM systems)  
- **Draw.io** â€“ Architecture, data flow, and data model diagrams  
- **Git & GitHub** â€“ Version control  
- **Notion** â€“ Project planning and documentation  
- **AI-assisted development tools** â€“ For coding, debugging, and optimization  

---

## ğŸš€ Project Requirements

### Data Warehouse (Data Engineering)

#### Objective
Build a modern data warehouse using **PostgreSQL** to consolidate sales data from multiple source systems and enable analytical reporting.

#### Specifications
- **Data Sources**  
  - ERP and CRM datasets provided as CSV files  

- **Data Quality**  
  - Clean and validate data before analysis  

- **Integration**  
  - Combine multiple sources into a unified analytical model  

- **Scope**  
  - Focus on the latest snapshot of data (no historization or SCD handling)  

- **Documentation**  
  - Provide clear documentation for data models and transformations  

---

### Analytics & Reporting

#### Objective
Develop SQL-based analytics to deliver insights into:
- Customer behavior  
- Product performance  
- Sales trends  

These insights can be used for dashboards and stakeholder reporting.

For more details, see `docs/requirements.md`.

---

## ğŸ“‚ Repository Structure

data-warehouse-project/
â”‚
â”œâ”€â”€ datasets/ # Raw CSV datasets (ERP and CRM)
â”‚
â”œâ”€â”€ docs/ # Documentation and diagrams
â”‚ â”œâ”€â”€ etl.drawio # ETL processes
â”‚ â”œâ”€â”€ data_architecture.drawio # Medallion architecture diagram
â”‚ â”œâ”€â”€ data_catalog.md # Dataset descriptions and metadata
â”‚ â”œâ”€â”€ data_flow.drawio # Data flow diagram
â”‚ â”œâ”€â”€ data_models.drawio # Star schema and data models
â”‚ â”œâ”€â”€ naming-conventions.md # Naming standards
â”‚
â”œâ”€â”€ scripts/ # SQL scripts
â”‚ â”œâ”€â”€ bronze/ # Raw data ingestion scripts
â”‚ â”œâ”€â”€ silver/ # Data cleaning & transformation scripts
â”‚ â”œâ”€â”€ gold/ # Analytical models (facts & dimensions)
â”‚
â”œâ”€â”€ tests/ # Data quality and validation scripts
â”‚
â”œâ”€â”€ README.md # Project overview
â”œâ”€â”€ LICENSE # License information
â”œâ”€â”€ .gitignore # Git ignore rules
â””â”€â”€ requirements.txt # Project dependencies


---

## ğŸ›¡ï¸ License

This project is licensed under the **MIT License**.  
You are free to use, modify, and distribute this project with proper attribution.

---

## ğŸŒŸ About This Project

This project is a **hands-on learning and portfolio project**, inspired by real-world data engineering practices and implemented independently using **PostgreSQL**.

It emphasizes:
- Strong SQL fundamentals  
- Realistic data warehouse design  
- Clear documentation  
- Effective use of modern AI-assisted development tools  

---

